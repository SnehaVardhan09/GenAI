# Preference Alignment

Aligning language models with human preferences. 
SFT helps models learn task, Preference alignment encourages outputs to match human expectations and values.