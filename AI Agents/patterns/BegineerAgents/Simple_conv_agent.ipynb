{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Conversational Agent with Context Awareness\n",
    "- Creating a conv agent that maintains context across multiple interactions.\n",
    "- Many Simple chatbots lacks to maintain context, leading to disjoint and frustrating user experience.\n",
    "- Solving this prob by implementing a conversational agent that can remember and refer to previous parts of the conversation.\n",
    "\n",
    "\n",
    "## Components\n",
    "- Language Model\n",
    "- Prompt template\n",
    "- History Manager\n",
    "- Message Store\n",
    "\n",
    "## Method Details\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Creating the Chat History Store - to manage multiple conversation sessions.\n",
    "3. Defining the Conversation Structure \n",
    "    * A system message defining the AI's role.\n",
    "    * A placeholder for conversation history\n",
    "    * The user's input\n",
    "4. Building the Conversation Chain\n",
    "5. Interacting with the agent\n",
    "\n",
    "## Conclusion \n",
    "* Context Awareness\n",
    "* Simplicity\n",
    "* Flexibility\n",
    "* Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model= 'gemma:2b',temperature= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple in-memory store for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the prompt and model into a runnable chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the chain with message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key = \"input\",\n",
    "    history_messages_key = \"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example useage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Sure, I can help with that.\n",
      "\n",
      "I'm doing great! Thank you for your question. I'm here to assist you with any calculations you may need.\n",
      "\n",
      "To calculate your travel budget, we can use the following formula:\n",
      "\n",
      "```\n",
      "Budget = Base cost * (Discount percentage) - Initial cost\n",
      "```\n",
      "\n",
      "In this case:\n",
      "\n",
      "* Base cost = 5000\n",
      "* Discount percentage = 0.8 (80% in decimal)\n",
      "* Initial cost = 750\n",
      "\n",
      "Plugging these values into the formula, we get:\n",
      "\n",
      "```\n",
      "Budget = 5000 * 0.8 - 750 = 4000\n",
      "```\n",
      "\n",
      "Therefore, your travel budget is 4000.\n",
      "AI I'm doing great! Thank you for your question. I'm here to assist you with any calculations you may need.\n",
      "\n",
      "The result of 234 divided by 13 is approximately 18.54.\n",
      "AI: I am unable to access previous messages, so I cannot provide any information about your previous questions.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_01\"\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI\", response1)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's the result of 234 divided by 13?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI\", response2)\n",
    "\n",
    "response3 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous messages?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "human: Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\n",
      "ai: Sure, I can help with that.\n",
      "\n",
      "I'm doing great! Thank you for your question. I'm here to assist you with any calculations you may need.\n",
      "\n",
      "To calculate your travel budget, we can use the following formula:\n",
      "\n",
      "```\n",
      "Budget = Base cost * (Discount percentage) - Initial cost\n",
      "```\n",
      "\n",
      "In this case:\n",
      "\n",
      "* Base cost = 5000\n",
      "* Discount percentage = 0.8 (80% in decimal)\n",
      "* Initial cost = 750\n",
      "\n",
      "Plugging these values into the formula, we get:\n",
      "\n",
      "```\n",
      "Budget = 5000 * 0.8 - 750 = 4000\n",
      "```\n",
      "\n",
      "Therefore, your travel budget is 4000.\n",
      "human: What's the result of 234 divided by 13?\n",
      "ai: I'm doing great! Thank you for your question. I'm here to assist you with any calculations you may need.\n",
      "\n",
      "The result of 234 divided by 13 is approximately 18.54.\n",
      "human: What was my previous messages?\n",
      "ai: I am unable to access previous messages, so I cannot provide any information about your previous questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation History:\")\n",
    "for message in store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Sure, here's the calculated travel budget from the context:\n",
      "\n",
      "5000 * 0.8 - 750 = 4000 - 750 = 3250.\n",
      "\n",
      "Therefore, the travel budget is 3250.\n",
      "AI: The context does not provide any information about 234 divided by 13, so I cannot answer this question from the provided context.\n",
      "AI: The context does not provide any information about previous messages, so I cannot answer these questions from the provided context.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_01\"\n",
    "\n",
    "# Initialize the session history if not already done\n",
    "if 'session_history' not in globals():\n",
    "    session_history = {}\n",
    "\n",
    "# Function to invoke the chain with history\n",
    "def invoke_chain_with_history(input_text, session_id):\n",
    "    if session_id not in session_history:\n",
    "        session_history[session_id] = []\n",
    "    \n",
    "    # Add the new input to the session history\n",
    "    session_history[session_id].append(input_text)\n",
    "    \n",
    "    # Invoke the chain with the updated session history\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"input\": input_text, \"history\": session_history[session_id]},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    \n",
    "    # Add the response to the session history\n",
    "    session_history[session_id].append(response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "response1 = invoke_chain_with_history(\"Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\", session_id)\n",
    "print(\"AI:\", response1)\n",
    "\n",
    "response2 = invoke_chain_with_history(\"What's the result of 234 divided by 13?\", session_id)\n",
    "print(\"AI:\", response2)\n",
    "\n",
    "response3 = invoke_chain_with_history(\"What were my previous messages?\", session_id)\n",
    "print(\"AI:\", response3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
