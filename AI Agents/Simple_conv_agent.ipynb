{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Conversational Agent with Context Awareness\n",
    "- Creating a conv agent that maintains context across multiple interactions.\n",
    "- Many Simple chatbots lacks to maintain context, leading to disjoint and frustrating user experience.\n",
    "- Solving this prob by implementing a conversational agent that can remember and refer to previous parts of the conversation.\n",
    "\n",
    "\n",
    "## Components\n",
    "- Language Model\n",
    "- Prompt template\n",
    "- History Manager\n",
    "- Message Store\n",
    "\n",
    "## Method Details\n",
    "\n",
    "1. Setting up the environment\n",
    "2. Creating the Chat History Store - to manage multiple conversation sessions.\n",
    "3. Defining the Conversation Structure \n",
    "    * A system message defining the AI's role.\n",
    "    * A placeholder for conversation history\n",
    "    * The user's input\n",
    "4. Building the Conversation Chain\n",
    "5. Interacting with the agent\n",
    "\n",
    "## Conclusion \n",
    "* Context Awareness\n",
    "* Simplicity\n",
    "* Flexibility\n",
    "* Scalability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.memory import ChatMessageHistory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ollama pull gemma:2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaLLM(model= 'gemma:2b',temperature= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a simple in-memory store for chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = {}\n",
    "\n",
    "def get_chat_history(session_id):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([(\"system\", \"You are a helpful AI assistant\"),\n",
    "         MessagesPlaceholder(variable_name=\"history\"),\n",
    "         (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the prompt and model into a runnable chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap the chain with message history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_with_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_chat_history,\n",
    "    input_messages_key = \"input\",\n",
    "    history_messages_key = \"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example useage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI The AI does a great job calculating the travel budget using the provided formula! \n",
      "\n",
      "It clearly shows each step and the final result, making it easy to understand and follow.\n",
      "AI The context does not provide any information about 234 divided by 13, so I cannot answer this question from the provided context.\n",
      "AI: The context does not provide any information about previous messages, so I cannot answer this question from the provided context.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_01\"\n",
    "\n",
    "response1 = chain_with_history.invoke(\n",
    "    {\"input\": \"Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI\", response1)\n",
    "\n",
    "response2 = chain_with_history.invoke(\n",
    "    {\"input\": \"What's the result of 234 divided by 13?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI\", response2)\n",
    "\n",
    "response3 = chain_with_history.invoke(\n",
    "    {\"input\": \"What was my previous messages?\"},\n",
    "    config={\"configurable\": {\"session_id\": session_id}}\n",
    ")\n",
    "print(\"AI:\", response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conversation History:\n",
      "human: Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\n",
      "ai: Hello! I'm doing well, thanks for asking. I'm here to help with travel-related questions and tasks. \n",
      "\n",
      "What can I do for you today?\n",
      "human: Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\n",
      "ai: The AI calculates the travel budget as follows:\n",
      "\n",
      "5000 * 0.8 - 750 = 4000 - 750 = 3250.\n",
      "\n",
      "Therefore, the travel budget is 3250.\n",
      "human: Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\n",
      "ai: The AI does a great job calculating the travel budget using the provided formula! \n",
      "\n",
      "It clearly shows each step and the final result, making it easy to understand and follow.\n",
      "human: What's the result of 234 divided by 13?\n",
      "ai: The context does not provide any information about 234 divided by 13, so I cannot answer this question from the provided context.\n",
      "human: What was my previous messages?\n",
      "ai: The context does not provide any information about previous messages, so I cannot answer this question from the provided context.\n",
      "human: Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\n",
      "ai: Sure, here's the calculated travel budget from the context:\n",
      "\n",
      "5000 * 0.8 - 750 = 4000 - 750 = 3250.\n",
      "\n",
      "Therefore, the travel budget is 3250.\n",
      "human: What's the result of 234 divided by 13?\n",
      "ai: The context does not provide any information about 234 divided by 13, so I cannot answer this question from the provided context.\n",
      "human: What were my previous messages?\n",
      "ai: The context does not provide any information about previous messages, so I cannot answer these questions from the provided context.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConversation History:\")\n",
    "for message in store[session_id].messages:\n",
    "    print(f\"{message.type}: {message.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Sure, here's the calculated travel budget from the context:\n",
      "\n",
      "5000 * 0.8 - 750 = 4000 - 750 = 3250.\n",
      "\n",
      "Therefore, the travel budget is 3250.\n",
      "AI: The context does not provide any information about 234 divided by 13, so I cannot answer this question from the provided context.\n",
      "AI: The context does not provide any information about previous messages, so I cannot answer these questions from the provided context.\n"
     ]
    }
   ],
   "source": [
    "session_id = \"user_01\"\n",
    "\n",
    "# Initialize the session history if not already done\n",
    "if 'session_history' not in globals():\n",
    "    session_history = {}\n",
    "\n",
    "# Function to invoke the chain with history\n",
    "def invoke_chain_with_history(input_text, session_id):\n",
    "    if session_id not in session_history:\n",
    "        session_history[session_id] = []\n",
    "    \n",
    "    # Add the new input to the session history\n",
    "    session_history[session_id].append(input_text)\n",
    "    \n",
    "    # Invoke the chain with the updated session history\n",
    "    response = chain_with_history.invoke(\n",
    "        {\"input\": input_text, \"history\": session_history[session_id]},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "    \n",
    "    # Add the response to the session history\n",
    "    session_history[session_id].append(response)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Example usage\n",
    "response1 = invoke_chain_with_history(\"Hello! How are you, Calculate my travel budget: 5000 * 0.8 - 750\", session_id)\n",
    "print(\"AI:\", response1)\n",
    "\n",
    "response2 = invoke_chain_with_history(\"What's the result of 234 divided by 13?\", session_id)\n",
    "print(\"AI:\", response2)\n",
    "\n",
    "response3 = invoke_chain_with_history(\"What were my previous messages?\", session_id)\n",
    "print(\"AI:\", response3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AIagents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
